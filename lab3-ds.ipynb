{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8972938,"sourceType":"datasetVersion","datasetId":5393336}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Laboratorio 3\nintegrantes:\n\n- Francis Aguilar - 22243\n- César López - 22535\n- Angela García -22869\n \nenlace al repositorio: https://www.kaggle.com/code/angelargd8/lab3-ds","metadata":{}},{"cell_type":"code","source":"!pip install tensorflow","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T22:37:47.029585Z","iopub.execute_input":"2025-07-31T22:37:47.030275Z","iopub.status.idle":"2025-07-31T22:37:50.964763Z","shell.execute_reply.started":"2025-07-31T22:37:47.030238Z","shell.execute_reply":"2025-07-31T22:37:50.963761Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.utils import to_categorical\nimport matplotlib.pyplot as plt\nimport pickle\nimport os\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\nfrom PIL import Image","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-31T22:37:50.966683Z","iopub.execute_input":"2025-07-31T22:37:50.967003Z","iopub.status.idle":"2025-07-31T22:37:50.973175Z","shell.execute_reply.started":"2025-07-31T22:37:50.966972Z","shell.execute_reply":"2025-07-31T22:37:50.972205Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Análisis exploratorio","metadata":{}},{"cell_type":"code","source":"print(\"Contenido de /kaggle/input:\")\nprint(os.listdir(\"/kaggle/input\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T22:37:50.974386Z","iopub.execute_input":"2025-07-31T22:37:50.974733Z","iopub.status.idle":"2025-07-31T22:37:51.004779Z","shell.execute_reply.started":"2025-07-31T22:37:50.974699Z","shell.execute_reply":"2025-07-31T22:37:51.003628Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"base_root = \"/kaggle/input/mnist-multiple-dataset-comprehensive-analysis\"\n\nprint(\"Contenido dentro del dataset:\")\nprint(os.listdir(base_root))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T22:37:51.007190Z","iopub.execute_input":"2025-07-31T22:37:51.007525Z","iopub.status.idle":"2025-07-31T22:37:51.044274Z","shell.execute_reply.started":"2025-07-31T22:37:51.007503Z","shell.execute_reply":"2025-07-31T22:37:51.043137Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"poly_path = \"/kaggle/input/mnist-multiple-dataset-comprehensive-analysis/PolyMNIST\"\nprint(\"Contenido en PolyMNIST:\", os.listdir(poly_path))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T22:37:51.045347Z","iopub.execute_input":"2025-07-31T22:37:51.045629Z","iopub.status.idle":"2025-07-31T22:37:51.053032Z","shell.execute_reply.started":"2025-07-31T22:37:51.045609Z","shell.execute_reply":"2025-07-31T22:37:51.052265Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mmnist_path = os.path.join(poly_path, \"MMNIST\")\nprint(\"Contenido en MMNIST:\", os.listdir(mmnist_path))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T22:37:51.054468Z","iopub.execute_input":"2025-07-31T22:37:51.054920Z","iopub.status.idle":"2025-07-31T22:37:51.075685Z","shell.execute_reply.started":"2025-07-31T22:37:51.054889Z","shell.execute_reply":"2025-07-31T22:37:51.074685Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_path = os.path.join(mmnist_path, \"train\")\nprint(\"Contenido en train:\", os.listdir(train_path))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T22:37:51.076661Z","iopub.execute_input":"2025-07-31T22:37:51.076968Z","iopub.status.idle":"2025-07-31T22:37:51.098793Z","shell.execute_reply.started":"2025-07-31T22:37:51.076927Z","shell.execute_reply":"2025-07-31T22:37:51.097928Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El conjunto de datos de polyMNIST tiene cinco modalidades distintas. El fondo de cada modalidad se compone de parches aleatorios recortados de una imagen más grande, con el dígito colocado aleatoriamente dentro de estos parches. Esta configuración proporciona a cada modalidad información única de su imagen de fondo, mientras que el dígito sirve como información compartida entre todas las modalidades. Un desafío adicional, en comparación con el PolyMNIST original, es la traducción aleatoria de los dígitos.\n\nDescripción tomada de: https://www.kaggle.com/datasets/agungpambudi/mnist-multiple-dataset-comprehensive-analysis/data","metadata":{}},{"cell_type":"markdown","source":"En el conjunto de datos, algo importante de ver antes de colocar los datos en un dataframe, es que el nombre de los archivos tiene el siguiente formato:\n\n**id.etiqueta.png**\n","metadata":{}},{"cell_type":"code","source":"#leer las imagenes del dataset y extraer sus etiquetas \nbase_path = \"/kaggle/input/mnist-multiple-dataset-comprehensive-analysis/PolyMNIST/MMNIST/train\"\n\ndata = []\nfor root, dirs, files in os.walk(base_path):\n    for file in files:\n        if file.endswith(\".png\"):\n            full_path = os.path.join(root, file)\n            label = file.split('.')[1]\n            data.append((full_path, int(label)))\n\ndf = pd.DataFrame(data, columns=[\"filepath\", \"label\"])\nprint(df.head(), \"\\nTotal imágenes:\", len(df))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T22:37:51.099726Z","iopub.execute_input":"2025-07-31T22:37:51.100067Z","iopub.status.idle":"2025-07-31T22:44:58.381621Z","shell.execute_reply.started":"2025-07-31T22:37:51.100037Z","shell.execute_reply":"2025-07-31T22:44:58.380531Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Primeras filas del DataFrame:\")\nprint(df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T22:44:58.382606Z","iopub.execute_input":"2025-07-31T22:44:58.382887Z","iopub.status.idle":"2025-07-31T22:44:58.390246Z","shell.execute_reply.started":"2025-07-31T22:44:58.382864Z","shell.execute_reply":"2025-07-31T22:44:58.389273Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Ver tamaño del dataset\nprint(\"\\nNúmero total de imágenes:\", len(df))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T22:44:58.392789Z","iopub.execute_input":"2025-07-31T22:44:58.393219Z","iopub.status.idle":"2025-07-31T22:44:58.418781Z","shell.execute_reply.started":"2025-07-31T22:44:58.393191Z","shell.execute_reply":"2025-07-31T22:44:58.417779Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#imagenes por cada carpeta\ndf['folder'] = df['filepath'].apply(lambda x: x.split('/')[-2])\nsns.countplot(data=df, x=\"folder\")\nplt.title(\"Distribución por fuente (carpeta)\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T22:44:58.884306Z","iopub.execute_input":"2025-07-31T22:44:58.884559Z","iopub.status.idle":"2025-07-31T22:44:59.389871Z","shell.execute_reply.started":"2025-07-31T22:44:58.884541Z","shell.execute_reply":"2025-07-31T22:44:59.388805Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sns.countplot(data=df, x=\"label\")\nplt.title(\"Distribución de clases\")\nplt.xlabel(\"Etiqueta\")\nplt.ylabel(\"Cantidad de imágenes\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T22:44:58.419819Z","iopub.execute_input":"2025-07-31T22:44:58.420458Z","iopub.status.idle":"2025-07-31T22:44:58.883568Z","shell.execute_reply.started":"2025-07-31T22:44:58.420427Z","shell.execute_reply":"2025-07-31T22:44:58.882560Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"La distribución de clases no parece tener un gran desbalance, sin embargo es ideal que este balanceada. En este caso se usara unsersampling, ya que son muchos datos y no tienen una gran diferencia en cuanto datos.","metadata":{}},{"cell_type":"code","source":"#balancear las clases, esta vez undersampling porque muy grande el dataset\nfrom sklearn.utils import resample\n\nmin_count = df['label'].value_counts().min()\ndf = pd.concat([\n    resample(df[df['label'] == label], replace=False, n_samples=min_count, random_state=42)\n    for label in df['label'].unique()\n])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sns.countplot(data=df, x=\"label\")\nplt.title(\"Distribución de clases\")\nplt.xlabel(\"Etiqueta\")\nplt.ylabel(\"Cantidad de imágenes\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Duplicados por nombre\nprint(\"Duplicados:\", df.duplicated(\"filepath\").sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T22:44:59.390863Z","iopub.execute_input":"2025-07-31T22:44:59.391137Z","iopub.status.idle":"2025-07-31T22:44:59.464284Z","shell.execute_reply.started":"2025-07-31T22:44:59.391118Z","shell.execute_reply":"2025-07-31T22:44:59.463291Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Tamaños de imagen\ndf['size'] = df['filepath'].apply(lambda path: Image.open(path).size)\nprint(\"Tamaños únicos:\", df['size'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T22:44:59.465620Z","iopub.execute_input":"2025-07-31T22:44:59.465883Z","iopub.status.idle":"2025-07-31T23:06:37.707571Z","shell.execute_reply.started":"2025-07-31T22:44:59.465853Z","shell.execute_reply":"2025-07-31T23:06:37.706384Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from PIL import Image\nimport matplotlib.pyplot as plt\n\n# Asegura que la columna 'label' es int\ndf['label'] = df['label'].astype(int)\n\n# Obtener clases únicas\nunique_labels = sorted(df['label'].unique())\n\n# Mostrar una imagen por clase (máximo 10 si quieres limitar)\nplt.figure(figsize=(12, 4))\n\nfor i, label in enumerate(unique_labels[:10]):\n    subset = df[df['label'] == label]\n    if not subset.empty:\n        img_path = subset.iloc[0]['filepath']\n        img = Image.open(img_path)\n        plt.subplot(2, 5, i + 1)\n        plt.imshow(img, cmap='gray')\n        plt.title(f\"Etiqueta: {label}\")\n        plt.axis('off')\n\nplt.tight_layout()\nplt.suptitle(\"Ejemplo visual por clase\", y=1.05)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T23:06:37.708576Z","iopub.execute_input":"2025-07-31T23:06:37.708869Z","iopub.status.idle":"2025-07-31T23:06:38.401175Z","shell.execute_reply.started":"2025-07-31T23:06:37.708846Z","shell.execute_reply":"2025-07-31T23:06:38.400145Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"En los ejemplos, se logra observar que dataset tiene una alta variabilidad visual y estilo porque cada uno tiene colores, fondos, tipografía, estilo de escritura y ruido. Y hay ciertos números que puede que por su fondo que tienen mucho ruido pueda causar problemas con el entrenamiento.","metadata":{}},{"cell_type":"markdown","source":"#### Preparacion de datos","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport os\nimport numpy as np\n\n# Ruta base\nbase_path = \"/kaggle/input/mnist-multiple-dataset-comprehensive-analysis/PolyMNIST/MMNIST\"\n\n# Altura, ancho e input shape (ajustar si cambia)\nimg_height, img_width = 28, 28\ninput_shape = (img_height, img_width, 1)  # grayscale\nbatch_size = 64\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T23:18:14.936997Z","iopub.execute_input":"2025-07-31T23:18:14.937520Z","iopub.status.idle":"2025-07-31T23:18:14.949058Z","shell.execute_reply.started":"2025-07-31T23:18:14.937491Z","shell.execute_reply":"2025-07-31T23:18:14.947433Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom tqdm import tqdm\n\nimg_height, img_width = 28, 28\nbase_path = \"/kaggle/input/mnist-multiple-dataset-comprehensive-analysis/PolyMNIST/MMNIST\"\nmodalidades = ['m0', 'm1', 'm2', 'm3', 'm4']\n\ndef cargar_datos(modalidades, tipo='train'):\n    X = []\n    y = []\n\n    for mod in modalidades:\n        path = os.path.join(base_path, tipo, mod)\n        archivos = sorted(os.listdir(path))\n\n        for nombre in tqdm(archivos, desc=f'Cargando {tipo}/{mod}'):\n            if nombre.endswith('.png'):\n                etiqueta = int(float(nombre.split('.')[1]))\n                img_path = os.path.join(path, nombre)\n                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n                img = cv2.resize(img, (img_width, img_height))  # Asegura tamaño uniforme\n                img = img.astype('float32') / 255.0  # Normalizar\n\n                X.append(img)\n                y.append(etiqueta)\n\n    X = np.expand_dims(np.array(X), -1)\n    y = np.array(y)\n    return X, y\n\n# Cargar datos de entrenamiento y prueba desde modalidad m0\nX_train, y_train = cargar_datos(modalidades=['m0', 'm1', 'm2', 'm3', 'm4'], tipo='train')\nX_test, y_test = cargar_datos(modalidades=['m0', 'm1', 'm2', 'm3', 'm4'], tipo='test')\nprint(\"Clases:\", np.unique(y_train))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T00:43:12.238361Z","iopub.execute_input":"2025-08-01T00:43:12.239453Z","iopub.status.idle":"2025-08-01T00:59:57.187669Z","shell.execute_reply.started":"2025-08-01T00:43:12.239409Z","shell.execute_reply":"2025-08-01T00:59:57.186613Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Train:\", X_train.shape, y_train.shape)\nprint(\"Test:\", X_test.shape, y_test.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T23:33:52.649040Z","iopub.execute_input":"2025-07-31T23:33:52.649442Z","iopub.status.idle":"2025-07-31T23:33:52.655551Z","shell.execute_reply.started":"2025-07-31T23:33:52.649413Z","shell.execute_reply":"2025-07-31T23:33:52.654098Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Configuración básica\naltura, ancho, canales = img_height, img_width, 1\nnum_clases = len(np.unique(y_train))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T23:35:47.124708Z","iopub.execute_input":"2025-07-31T23:35:47.126026Z","iopub.status.idle":"2025-07-31T23:35:47.132787Z","shell.execute_reply.started":"2025-07-31T23:35:47.125953Z","shell.execute_reply":"2025-07-31T23:35:47.131598Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Funcion para evaluar modelos","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport warnings\nimport numpy as np\n\ndef evaluar_modelo(modelo, X_test, y_test, nombre=\"Modelo\"):\n    print(f\"\\n=== Evaluación de {nombre} ===\")\n    loss, acc = modelo.evaluate(X_test, y_test, verbose=0)\n    print(f\"Accuracy: {acc:.4f} - Loss: {loss:.4f}\\n\")\n\n    y_pred = modelo.predict(X_test)\n    y_pred_classes = np.argmax(y_pred, axis=1)\n\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")\n        print(classification_report(y_test, y_pred_classes, zero_division=0))\n\n    cm = confusion_matrix(y_test, y_pred_classes)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n    plt.title(f'Matriz de Confusión - {nombre}')\n    plt.xlabel('Predicción')\n    plt.ylabel('Etiqueta verdadera')\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T00:06:17.372765Z","iopub.execute_input":"2025-08-01T00:06:17.373150Z","iopub.status.idle":"2025-08-01T00:06:17.380861Z","shell.execute_reply.started":"2025-08-01T00:06:17.373126Z","shell.execute_reply":"2025-08-01T00:06:17.379711Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Modelo CNN - 1","metadata":{}},{"cell_type":"code","source":"model1 = models.Sequential([\n    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(altura, ancho, canales)),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Flatten(),\n    layers.Dense(64, activation='relu'),\n    layers.Dense(num_clases, activation='softmax')\n])\n\nmodel1.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nmodel1.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T01:00:13.465339Z","iopub.execute_input":"2025-08-01T01:00:13.465741Z","iopub.status.idle":"2025-08-01T01:35:13.231738Z","shell.execute_reply.started":"2025-08-01T01:00:13.465716Z","shell.execute_reply":"2025-08-01T01:35:13.230576Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"evaluar_modelo(model1, X_test, y_test, \"CNN 1\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T01:43:58.529895Z","iopub.execute_input":"2025-08-01T01:43:58.530421Z","iopub.status.idle":"2025-08-01T01:44:27.057194Z","shell.execute_reply.started":"2025-08-01T01:43:58.530339Z","shell.execute_reply":"2025-08-01T01:44:27.056063Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Modelo CNN - 2","metadata":{}},{"cell_type":"code","source":"model2 = models.Sequential([\n    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(altura, ancho, canales)),\n    layers.BatchNormalization(),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.Dropout(0.3),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(128, (3, 3), activation='relu'),\n    layers.Flatten(),\n    layers.Dense(128, activation='relu'),\n    layers.Dropout(0.5),\n    layers.Dense(num_clases, activation='softmax')\n])\n\nmodel2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nmodel2.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T01:49:02.839318Z","iopub.execute_input":"2025-08-01T01:49:02.840525Z","iopub.status.idle":"2025-08-01T02:43:00.618716Z","shell.execute_reply.started":"2025-08-01T01:49:02.840481Z","shell.execute_reply":"2025-08-01T02:43:00.617347Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"evaluar_modelo(model2, X_test, y_test, \"CNN 2\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T03:26:57.307098Z","iopub.execute_input":"2025-08-01T03:26:57.308320Z","iopub.status.idle":"2025-08-01T03:27:29.331375Z","shell.execute_reply.started":"2025-08-01T03:26:57.308285Z","shell.execute_reply":"2025-08-01T03:27:29.330222Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Conclusion:\nLuego de entrenar y comparar ambos modelos, notamos que los dos tienen un rendimiento bastante bueno al reconocer los dígitos. Sin embargo, el segundo modelo (CNN 2) fue un poco más preciso, especialmente en la validación con datos que no había visto antes. También tuvo un error menor y menos confusión entre los números parecidos. Por eso, decidimos quedarnos con el modelo CNN 2, ya que es más robusto y generaliza mejor en nuevas imágenes.\n\n","metadata":{}},{"cell_type":"markdown","source":"#### Modelo Red Neuronal Simple","metadata":{}},{"cell_type":"code","source":"model_simple = models.Sequential([\n    layers.Flatten(input_shape=(altura, ancho, canales)),\n    layers.Dense(128, activation='relu'),\n    layers.Dense(num_clases, activation='softmax')\n])\n\nmodel_simple.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nmodel_simple.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T02:43:00.621417Z","iopub.execute_input":"2025-08-01T02:43:00.621740Z","iopub.status.idle":"2025-08-01T03:02:56.387828Z","shell.execute_reply.started":"2025-08-01T02:43:00.621715Z","shell.execute_reply":"2025-08-01T03:02:56.386998Z"}},"outputs":[],"execution_count":null}]}